import pandas as pd
from sklearn.feature_selection import VarianceThreshold
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import ElasticNetCV
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
import os
import pathlib

# ========== æ–‡ä»¶è·¯å¾„ ==========
file_path_step1 = r'C:\Users\xiaoping\Desktop\fushi\data\radiomics_54.csv'
output_file_dir = r'C:\Users\xiaoping\Desktop\fushi\data\variance_filtered'
os.makedirs(output_file_dir, exist_ok=True)
output_file_path = os.path.join(output_file_dir,'merge_features_54.csv')
# ========== ç¬¬ä¸€æ­¥ï¼šå»é™¤é›¶æ–¹å·®ç‰¹å¾ ==========
data_step1 = pd.read_csv(file_path_step1)   #è¯»å–æ•°æ®
X_step1 = data_step1.iloc[:, 1:]
X_numeric = X_step1.select_dtypes(include=['number'])  # ä»…ä¿ç•™æ•°å€¼åˆ—

selector = VarianceThreshold(threshold=0)
X_zero_var = selector.fit_transform(X_numeric)
selected_columns_step1 = X_numeric.columns[selector.get_support()]  # æå–ä¿ç•™ä¸‹æ¥çš„ç‰¹å¾å
print(f"å»é™¤é›¶æ–¹å·®åå‰©ä½™ç‰¹å¾æ•°: {len(selected_columns_step1)}")

# ========== ç¬¬äºŒæ­¥ï¼šå»é™¤æ–¹å·®å¤„äºæœ€ä½ 5% çš„ç‰¹å¾ ==========
X_step2 = X_numeric[selected_columns_step1]

# âš ï¸ åŸºäºåŸå§‹å°ºåº¦è®¡ç®—æ–¹å·®
variances = X_step2.var()
threshold_value = np.percentile(variances, 5)  # å»æ‰æ–¹å·®æœ€ä½ 5%
selected_columns_step2 = variances[variances > threshold_value].index
print(f"è¿›ä¸€æ­¥å»æ‰æ–¹å·®æœ€ä½ 5% åå‰©ä½™ç‰¹å¾æ•°: {len(selected_columns_step2)}")

# âœ… åœ¨ç­›é€‰å®Œåå†åšæ ‡å‡†åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_step2[selected_columns_step2])
X_scaled_df = pd.DataFrame(X_scaled, columns=selected_columns_step2)


data_filtered = pd.concat([data_step1[['Time(h)']], X_scaled_df[selected_columns_step2]], axis=1) # æ‹¼æ¥æ—¶é—´åˆ— + æ ‡å‡†åŒ–åçš„ç‰¹å¾
data_filtered.to_csv(output_file_path, index=False)
print(f"ç­›é€‰åçš„æ•°æ®å·²ä¿å­˜ä¸º: {output_file_path}")

# ========== ç¬¬ä¸‰æ­¥ï¼šå»æ‰ä¸¤ç‰¹å¾ç›¸å…³å…³ç³»ç³»æ•°å¤§äº0.9çš„ç‰¹å¾ä¹‹ä¸€==========
file_path_step3 = r"C:\Users\xiaoping\Desktop\fushi\data\variance_filtered\merge_features_54.csv" # è¾“å…¥è¾“å‡ºè·¯å¾„
file_stem = pathlib.Path(file_path_step3).stem
output_dir = r"C:\Users\xiaoping\Desktop\fushi\data\features_selected_54"
os.makedirs(output_dir, exist_ok=True)

print("ğŸ“‚ æ­£åœ¨è¯»å–æ•°æ®â€¦â€¦")
data_step3 = pd.read_csv(file_path_step3)

y_step3 = data_step3.iloc[:, 0].astype(float)  # ç›®æ ‡å˜é‡ (æ—¶é—´åˆ—ç¬¬ä¸€åˆ—)
X_step3 = data_step3.iloc[:, 1:]  # ç‰¹å¾åˆ—

enet = ElasticNetCV(cv=5, random_state=42, l1_ratio=0.5) # ç”¨ ElasticNet è®¡ç®—ç‰¹å¾æƒé‡ï¼ˆåœ¨åŸå§‹æ•°æ®ä¸Šï¼‰
enet.fit(X_step3, y_step3)
coef = pd.Series(enet.coef_, index=X_step3.columns)

# ğŸ”¹ã€æ–°å¢1ã€‘ï¼šä¿å­˜ ElasticNet å„ç‰¹å¾ç³»æ•°
coef_df = pd.DataFrame({
    "Feature": coef.index,
    "ElasticNet_Coefficient": coef.values
})
# coef_path = os.path.join(output_dir, f"{file_stem}_elasticnet_coefficients.csv")
# coef_df.to_csv(coef_path, index=False, encoding='utf-8-sig')
# print(f"âœ… å·²ä¿å­˜ ElasticNet ç‰¹å¾ç³»æ•°: {coef_path}")


#  1ï¸âƒ£ ç›¸å…³æ€§ç­›é€‰
final_selected_features = X_step3.columns.tolist()

while True:
    corr_df = X_step3[final_selected_features].corr()
    to_remove = set()

    for i in range(len(corr_df.columns)):
        for j in range(i + 1, len(corr_df.columns)):
            if abs(corr_df.iloc[i, j]) > 0.9:
                f1, f2 = corr_df.columns[i], corr_df.columns[j]
                # ä¿ç•™æƒé‡ç»å¯¹å€¼æ›´å¤§çš„ç‰¹å¾
                if abs(coef[f1]) >= abs(coef[f2]):
                    to_remove.add(f2)
                else:
                    to_remove.add(f1)

    if not to_remove:
        break

    final_selected_features = [f for f in final_selected_features if f not in to_remove]

# ğŸ”¹ã€æ–°å¢2ã€‘ï¼šä¿å­˜ç‰¹å¾é—´çš„ç›¸å…³ç³»æ•°çŸ©é˜µ
corr_matrix = X_step3[final_selected_features].corr()
corr_matrix_path = os.path.join(output_dir, f"{file_stem}_feature_correlation.csv")
corr_matrix.to_csv(corr_matrix_path, encoding='utf-8-sig')

print(f"âœ… å·²ä¿å­˜ç‰¹å¾é—´ç›¸å…³ç³»æ•°çŸ©é˜µ: {corr_matrix_path}")
print(f"ç›¸å…³æ€§ç­›é€‰åå‰©ä½™ç‰¹å¾æ•°: {len(final_selected_features)}")
print("ç›¸å…³æ€§ç­›é€‰åç‰¹å¾ï¼š", final_selected_features)

corr_selected_data = data_step3[['Time(h)'] + final_selected_features] # ä¿å­˜ç›¸å…³æ€§0.9ç‰¹å¾ç­›é€‰ç»“æœ
csv_path_corr = os.path.join(output_dir, f"{file_stem}_0.9.csv")
corr_selected_data.to_csv(csv_path_corr, index=False, encoding='utf-8-sig')
print(f"âœ… å·²ä¿å­˜ç›¸å…³æ€§ç­›é€‰ç»“æœ: {csv_path_corr}")

#  2ï¸âƒ£ å»æ‰æƒé‡ = 0 çš„ç‰¹å¾ 
final_selected_features_nonzero = [f for f in final_selected_features if coef[f] != 0]

print(f"æœ€ç»ˆç­›é€‰åå‰©ä½™ç‰¹å¾æ•°: {len(final_selected_features_nonzero)}")
print("æœ€ç»ˆç­›é€‰åç‰¹å¾ï¼š", final_selected_features_nonzero)
# ğŸ”¹ã€æ–°å¢1ã€‘ï¼šä¿å­˜ ElasticNet å„ç‰¹å¾ç³»æ•°
# ä» coef_df ä¸­æå–ç­›é€‰ç‰¹å¾å¯¹åº”çš„ç³»æ•°
selected_coefs = coef_df[coef_df["Feature"].isin(final_selected_features_nonzero)]
features = selected_coefs.iloc[:, 0]  # è·å–ç¬¬ä¸€åˆ—ï¼Œå³ç‰¹å¾å
coefficients = selected_coefs.iloc[:, 1]  # è·å–ç¬¬äºŒåˆ—ï¼Œå³ç³»æ•°å€¼

# åˆ›å»º DataFrame ç”¨äºä¿å­˜ç­›é€‰åçš„ç‰¹å¾åŠå…¶å¯¹åº”ç³»æ•°
coef_df_selected = pd.DataFrame({
    "Feature": features,
    "ElasticNet_Coefficient": coefficients
})
# æ‰“å°ä»¥æ£€æŸ¥
print(coef_df_selected.head())
# ä¿å­˜ä¸º CSV æ–‡ä»¶
coef_path = os.path.join(output_dir, f"{file_stem}_elasticnet_coefficients.csv")
coef_df_selected.to_csv(coef_path, index=False, encoding='utf-8-sig')
print(f"âœ… ç­›é€‰åçš„ç‰¹å¾ç³»æ•°å·²ä¿å­˜ä¸º: {coef_path}")

# ğŸ”¹ã€æ–°å¢2ã€‘ï¼šä¿å­˜ç‰¹å¾é—´çš„ç›¸å…³ç³»æ•°çŸ©é˜µ
corr_matrix = X_step3[final_selected_features_nonzero].corr()
corr_matrix_path = os.path.join(output_dir, f"{file_stem}_feature_correlation.csv")
corr_matrix.to_csv(corr_matrix_path, encoding='utf-8-sig')

print(f"âœ… å·²ä¿å­˜ç‰¹å¾é—´ç›¸å…³ç³»æ•°çŸ©é˜µ: {corr_matrix_path}")
print(f"ç›¸å…³æ€§ç­›é€‰åå‰©ä½™ç‰¹å¾æ•°: {len(final_selected_features)}")
print("ç›¸å…³æ€§ç­›é€‰åç‰¹å¾ï¼š", final_selected_features)

final_selected_data = data_step3[['Time(h)'] + final_selected_features_nonzero] # ä¿å­˜å»æ‰æƒé‡ = 0 çš„ç‰¹å¾ç»“æœ
csv_path_final = os.path.join(output_dir, f"{file_stem}_0.csv")
final_selected_data.to_csv(csv_path_final, index=False, encoding='utf-8-sig')

print(f"ğŸ¯ å·²ä¿å­˜æœ€ç»ˆç­›é€‰åçš„æ•°æ®ä¸º: {csv_path_final}")
print("âœ… ç¬¬ä¸‰æ­¥ç¨‹åºæ‰§è¡Œå®Œæ¯•ã€‚")

# ========== ç¬¬å››æ­¥ï¼šç»˜åˆ¶çƒ­åŠ›å›¾ + ç³»æ•°æ•£ç‚¹å›¾ ==========
X_final = data_step3[final_selected_features_nonzero] # å–æœ€ç»ˆéé›¶ç‰¹å¾å¯¹åº”çš„æ•°æ®

# 1ï¸âƒ£ çƒ­åŠ›å›¾ï¼ˆCorrelation Heatmapï¼‰
plt.figure(figsize=(8, 8))
sns.heatmap(X_final.corr(), cmap="coolwarm", annot=False, square=True, cbar=True)
plt.title("Correlation Heatmap of Selected Features", fontsize=12)
plt.tight_layout()

heatmap_path = os.path.join(output_dir, f"{file_stem}_heatmap.png")
plt.savefig(heatmap_path, dpi=300)
plt.close()
print(f"ğŸ“Š å·²ä¿å­˜ç›¸å…³æ€§çƒ­åŠ›å›¾: {heatmap_path}")

# 2ï¸âƒ£ ç³»æ•°æ•£ç‚¹å›¾ï¼ˆCoefficient Scatter Plotï¼‰
coefs_nonzero = coef[final_selected_features_nonzero]

plt.figure(figsize=(8, 8))
plt.scatter(coefs_nonzero.index, coefs_nonzero.values, color="blue", alpha=0.7)
plt.axhline(y=0, color="gray", linestyle="--", linewidth=1)

plt.xticks(rotation=90)
plt.xlabel("Features")
plt.ylabel("ElasticNet Coefficient")
plt.title("ElasticNet Non-zero Feature Coefficients", fontsize=12)

plt.tight_layout()
scatter_path = os.path.join(output_dir, f"{file_stem}_coef_scatter.png")
plt.savefig(scatter_path, dpi=300)
plt.close()
print(f"ğŸ“Š å·²ä¿å­˜ç³»æ•°æ•£ç‚¹å›¾: {scatter_path}")




